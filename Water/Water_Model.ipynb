{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kNqmG6ULcxjf"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('water_potability.csv')\n"
      ],
      "metadata": {
        "id": "PUFcof9fIo5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.fillna(df.mean(), inplace=True)\n",
        "\n",
        "# Normalize numeric features\n",
        "scaler = MinMaxScaler()\n",
        "df[['ph', 'Hardness', 'Solids', 'Chloramines', 'Sulfate', 'Conductivity', 'Organic_carbon', 'Trihalomethanes', 'Turbidity']] = scaler.fit_transform(df[['ph', 'Hardness', 'Solids', 'Chloramines', 'Sulfate', 'Conductivity', 'Organic_carbon', 'Trihalomethanes', 'Turbidity']])"
      ],
      "metadata": {
        "id": "WgG2gmGjItKu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Feature Selection\n",
        "# Step 3: Model Training\n",
        "X = df.drop('Potability', axis=1)\n",
        "y = df['Potability']\n"
      ],
      "metadata": {
        "id": "u_nTCD29IxGy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "SqIXPn0JJXus"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a deep learning model\n",
        "model = Sequential()\n",
        "model.add(Dense(32, activation='relu', input_dim=X_train.shape[1]))\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "OvAewi0eJcJd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=0)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5asqiziJgUF",
        "outputId": "c1687a29-0530-42c6-90f1-d0c4afbd8b0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6d8bace950>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Model Evaluation\n",
        "# Make predictions on the testing set\n",
        "y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
        "\n",
        "\n",
        "# Evaluate the model's performance\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "confusion_mat = confusion_matrix(y_test, y_pred)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLtv9w-KJkkM",
        "outputId": "a4c75b68-6210-4838-9880-a446b2b1de51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21/21 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Accuracy: {accuracy:.2f}')\n",
        "print(f'Precision: {precision:.2f}')\n",
        "print(f'Recall: {recall:.2f}')\n",
        "print(f'F1-score: {f1:.2f}')\n",
        "print('Confusion Matrix:')\n",
        "print(confusion_mat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1_ZshlvKPzy",
        "outputId": "85964134-0b26-4f7d-d43b-f84177e28bca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.68\n",
            "Precision: 0.62\n",
            "Recall: 0.39\n",
            "F1-score: 0.48\n",
            "Confusion Matrix:\n",
            "[[352  60]\n",
            " [148  96]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"water_model.h5\")"
      ],
      "metadata": {
        "id": "VHqvJ8H7MNqi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Step 1: Data Preparation\n",
        "df = pd.read_csv('water_potability.csv')\n",
        "\n",
        "# Handle missing values if any\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Step 2: Statistical Analysis\n",
        "# Calculate statistical measures for each parameter\n",
        "statistical_measures = df.describe()\n",
        "\n",
        "# Step 3: Anomaly Detection Algorithm\n",
        "# Select features for anomaly detection\n",
        "features = ['ph', 'Hardness', 'Solids', 'Chloramines', 'Sulfate', 'Conductivity', 'Organic_carbon', 'Trihalomethanes', 'Turbidity']\n",
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "df_scaled = scaler.fit_transform(df[features])\n",
        "\n",
        "def generate_alert():\n",
        "    # Implement your alert/notification logic here\n",
        "    pass\n",
        "\n",
        "# Train the anomaly detection algorithm (Isolation Forest)\n",
        "anomaly_detector = IsolationForest(contamination=0.05)  # Adjust the contamination parameter as needed\n",
        "anomaly_detector.fit(df_scaled)\n",
        "\n",
        "# Step 4: Real-Time Monitoring\n",
        "# Continuously monitor incoming water quality data from API\n",
        "api_url = 'https://your-api-url.com'  # Replace with your actual API URL\n",
        "\n",
        "while True:\n",
        "    # Fetch new data from API\n",
        "    response = requests.get(api_url)\n",
        "    new_data = response.json()\n",
        "\n",
        "    # Create a DataFrame from the new data\n",
        "    new_data_df = pd.DataFrame(new_data)\n",
        "\n",
        "    # Apply scaling to the new data\n",
        "    new_data_scaled = scaler.transform(new_data_df[features])\n",
        "\n",
        "    # Predict the anomaly score for the new data\n",
        "    anomaly_score = anomaly_detector.predict(new_data_scaled)\n",
        "\n",
        "    # Step 5: Alert Generation\n",
        "    if anomaly_score == -1:\n",
        "        # Anomaly detected, generate alert/notification\n",
        "        generate_alert()\n"
      ],
      "metadata": {
        "id": "IjomzKTqQ3NB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}